\section*{Research Methodology}

We have two primary aims for our analysis in this chapter. First, we are interested in evaluating the relationships between different predictor variables and the occurrence of protest events at the country level. To do this we first present a series of simple count models where we predict the number of protest events in a country--year as a function of several predictor variables. More specifically, we are also interested in what, if any, causal effect US military deployments have on protest activity at the country level. To address this more specific question we use a number of more advanced techniques to identify this specific causal relationship. Second, we are also interested understanding the factors that correlate with individual-level protest involvement. We build a series of predictive models of individual protest participation. Accordingly, our analysis in this chapter has four primary parts and we begin by focusing on protest events at the country level, followed by protest participation at the individual level. 

This section focuses on 1) understanding the factors that correlate with country-level protest events, and the causal effects of US military deployments on the occurrence of protest events across countries, more specifically; and 2) generating a basic predictive model to help us understand the different types of people who are likely to participate in anti-US protest events, and to examine comparisons between different groups and their likelihood of engaging in protest activities.



\subsection*{Macro-Behavior Models: What Causes Anti-US Protest Events?}

Above we discuss our theoretical expectations concerning the link between US military deployments and macro-level protest events. In this section will discuss the data collection, operationalization, and estimation strategies we adopt to assess the causal effects of our variables of interest. 

In this chapter, we use two country-level measures of anti-US protest---protests against the United States, in general, and protests against the US military, specifically. These variables are counts of the number of protest events that occur in a given country in a given year. To generate these variables, we use events data on worldwide protest events between 1990 and 2018 gathered from the Integrated Data for Events Analysis (IDEA) dataset \cite{Bond2003}. The dataset compiles events from a range of global news sources. Through a mixture of automated parsing procedures and manual data review, we refined the general search to focus on various types of protest events that involved 1) the mass physical mobilization of individuals, and 2) protest events that were aimed at the United States government, in general, or the United States military, specifically.\footnote{We selected all instances of protest events, which include protest demonstrations (event code 181, ``All protest demonstrations not otherwise specified''), protest obstruction (event code 1811, ``sit-ins and other non-military occupation protests''), protest procession (event code 1812, ``picketing and other parading protests''), protest defacement (event code 1813, ``damage, sabotage and the use of graffiti to desecrate property and symbols''), and protest altruism (event code 1814, ``protest demonstrations that place the source [protestor] at risk for the sake of unity with the target'').}

%\footnote{Interview subjects across different countries noted that there had been an increase in anti-US protests since Donald Trump became President of the United States in 2016, while we cannot control for the ``Trump effect'' in our micro level analysis, as interviews were conducted in 2018, 2019, and 2020, in our macro-level analysis we account for this by taking annual measures into account \textbf{stuff for flynn to fill in} \cite{journ20180713,mpone20190717}.}

The IDEA dataset identifies protest events as an action taken by one actor (the sender) towards another actor (the target). Both senders and targets can be parsed to varying levels of specificity. For our purposes we adopt focus on two specific sets of actors, as discussed above. First, we selected all cases in which the database identifies the target country as the United States, regardless of the more specific target (i.e. civilian government officials, military, etc.). For example, protests of the election of US President Donald Trump would be in this category. Our sample includes 531 cases of anti-US protests, distributed throughout time and space.\footnote{In some cases the events data lists the location of the protest broadly as a region such as ``Western Africa,'' or even more broadly, as ``World.'' Because the data does not include enough detail for us to identify the specific country or countries in which these protests occurred, we drop these cases from the sample.}

For our second measure, we further narrow our focus to protests that target the US military. In this case, we take the sample of anti-US protests and select the cases in which the target is identified as being the military; the data defines this as, ``official armed forces, peacekeepers, astronauts, military police, military justice officers, military academies, and border guards'' \cite{Bond2003}. This gives us a total of 29 anti-US military protest observations, with Afghanistan, Australia, Iraq, and South Korea having the highest numbers of anti-military protests. As with the more general protest measure, we omit cases that occur within the United States.

While our outcome measures focus on protests directed against the United States, the data collection process also produced a measure of total protests in each country-year. This offers a baseline of comparison for anti-US protests as it is likely the case that people in some countries are more likely to protest in general than they are in others. We note that the data set collects the protest data at the country-month level (meaning events are coded for every month), though in our analysis we aggregate it to the country-year level given that our other variables of interest are at the country-year level of analysis.  This allows us to calculate a variable that is the number of anti-US protests in a country year as a proportion of total protests, thus allowing us to both control for greater inclination towards protest in some countries as well as to study whether there is something specific about anti-US protests that makes their determinants different from protests overall. In addition, we create a metric that measures anti-US military protests as a proportion of all anti-US protests; this again allows us to test whether different factors determine whether people are likely to protest against the US military in particular or whether these are just a subset of anti-US protests that are determined by the same factors as non-military focused protests.           


\subsubsection*{Model Specification and Identification}

%Political openness (squared term to capture curvilinear relationship)

We approach our analysis of country-level protest events in two steps. First, drawing on the theoretical arguments outlined in the previous section we present four Bayesian multilevel negative binomial count models where we model protest events as a function of several predictor variables for the 1990--2018 period. These initial models will provide us with a baseline set of relationships to better inform our understanding of the correlates of protest events against the United States. 

We intend the second approach to examine the more complicated question of identifying the causal effect of US military deployments on protest activity. Several factors complicate the accurate assessment of the \textit{causal} effect of deployments of protest. Traditional regression approaches are limited in their ability to estimate causal effects for a number of reasons. One of the most difficult problems to deal with is that the history of military deployments is likely to matter as much as short-term deployments, but basic regression models typically only provide estimates of short-term effects. Further, these histories are highly variable across countries. This can severely bias the estimates from our model, as not every country has an equal opportunity of experiencing US military deployments---both in terms of hosting them, but also with respect to the size of those deployments. Finally, as is often the case, the relationship between military deployments and protest events may suffer from confounding effects as other variables may exert a causal effect on both of our variables of interest. Accordingly, modeling protest events as a function of military deployments and adjusting for many other variables will not yield results that have any meaningful interpretation as causal effects. 

To address these problems, we estimate a marginal structural model (MSM) \cite{Robinsetal2000,BlackwellGlynn2018}. These models have a fairly long history of use in fields like biostatistics and epidemiology and can be used to help estimate causal effects in observational studies where exposure to treatments varies across space and time. They can also be used to help us estimate the contemporaneous effect of a treatment, as well as the more general effect of a particular treatment history. However, MSMs require us to do some additional work before we can estimate the effects of troop deployments and their histories on the outcome of interest. There are likely to be systematic differences between the individual countries that receive troop deployments, or larger deployments, and those that receive no, or smaller deployments. Additionally, troop deployments in a given period (what we refer to as time $t$) are heavily dependent on deployments in the previous period (time $t-1$). Deployments at time $t-1$ are also likely to affect other predictor variables in subsequent periods. To resolve this, we must estimate a series of structural weights for each observation to be used in the final regression model. We calculate these weights using the formula found in Appendix section \ref{eq:structuralweights}.



More simply, the weights shown in Equation \ref{eq:structuralweights} are a form of propensity score that we can use to re-balance the observations in our data. This is simply a variant of the inverse probability of treatment (IPTW) weighting method.\footnote{See \citeasnoun[Chapter 13]{ImbensRubin2015} for more information on estimating propensity scores.} Normally estimating propensity scores is a relatively straightforward process as it is commonly used to estimate scores in data where the treatment, and often the outcome, are binary (meaning 0 or 1) variables. The fact that our treatment (the number of US troops present in a country) is continuous (meaning that it can in theory take on any integer value that is 0 or greater) complicates this process slightly.\footnote{For a fuller discussion of estimating inverse probability of treatment weights for MSMs see \citeasnoun{ColeHernan2008}. For a discussion of estimating these weights for continuous treatment variables see \citeasnoun{vanderwalGEskus2011} and \citeasnoun{Naimietal2014}. Finally, for a discussion of estimating weights for a continuous treatment in the presence of multilevel/grouped data using multilevel models, see \citeasnoun{SchulerChuCoffman2016}.} To generate these weights we first have to estimate two separate models wherein troop deployments themselves are the outcome of interest. The first of these models (the numerator) is relatively straightforward to estimate. Here we are running a regression model wherein we predict the size of the troop deployments in country $i$ at time $t$ as a function of a one-unit lag of the troop deployment variable, the cumulative sum of troop deployments in country $i$ from the beginning of its series up through time $t-2$, and a range of time-invariant covariates, $Z$. In cases where researchers are working with just a binary treatment variable and only a single period, using ``1'' as the numerator is often all that is required. However, given that we are dealing with a continuous treatment variable, generating the numerator using this regression-based approach can help to stabilize the resulting weights by ensuring that the ratios are not enormous (see \citeasnoun{ColeHernan2008}).

The second model (the denominator) is more complicated. In most respects it is identical to the numerator, with the exception of the gamma ($\gamma$) term, which denotes a vector of covariates---the key here is that these covariates have to be sufficient to meet the sequential ignorability criteria. In essence, this is requires that there is no unmeasured confounding between the treatment (troops) and the outcome (protests).\footnote{The language on this point can be confusing given that these techniques were developed across several different literatures and disciplines and compounded by the fact that they often did not speak to one another. To put it in slightly different terms using language from \citeasnoun{Pearl2009}, this set of covariates must ensure that Pr$ (Y_{it} \Perp X_{it} | \gamma, Z_{i}) $. That is, the outcome is conditionally independent of the treatment, conditional upon the time-varying covariates ($\gamma$) and the time-invariant covariates ($Z$).} We will return to this below, but once we have both of these models we then generate two sets of predicted values and residuals for each observation in the data set---one using the numerator and one using the denominator. For each set of predictions and residuals we calculate the probability of the actual observed value of troops in country $i$ at time $t$ using the predictions and the standard deviation of the residuals as the mean and standard deviation of a normal probability density function. We then divide the values generated using the numerator figures by the values generated by the numerator. The actual structural weight for any given observation is the cumulative product of these ratios for country $i$ from the beginning of that country's series up through time $t$. 

This represents a brief overview of the process of estimating the structural weights. But, as we note above, estimating the second model is complicated by the fact that we need a set of covariates that ensure there is no unmeasured confounding between the treatment and outcome variables. To aid in this process we turn to another tool---directed acyclic graphs (DAGs). Like with MSMs, scholars from other disciplines have more commonly used DAGs (such as computer science and epidemiology) and they serve a variety of useful purposes. First, they help make explicit the wider array of theorized causal relationships between various predictor variables. Second, assuming a well-developed theoretical model, they can also help to identify sources of confounding and bias.\footnote{See \citeasnoun{Pearl2009}, \citeasnoun{MorganWinship2015}, and \citeasnoun{KeeleStevensonElwert2020} for a fuller discussion of DAGs and their applications.} Related, they can be used to identify which variables need to be adjusted for in a statistical model to close off the ``back-door'' paths between the treatment variable and the outcome that serve as the sources of confounding in the model, but also to ensure that we do not adjust for variables that may open up such informational pathways between the treatment and outcome and introduce additional sources of bias (i.e. collider bias) \cite{Pearl2009}.\footnote{We use the {\tt dagitty} package in {\tt R } to build our DAG and to identify possible adjustment sets \cite{Textoretal2016}.}

To estimate these models, we first begin by constructing a theoretical model wherein we treat protest events as the outcome of interest and military deployments as our key predictor, or ``treatment'' variable. These variables themselves are embedded in a larger theoretical causal framework where they are themselves caused by, and cause, a variety of other variables. Figure \ref{fig:dagtroops} presents a directed acyclic graph (DAG) depicting the basic contemporaneous relationships between the variables of interest and their relationships between two time periods, $t$ and $t+1$ (which is the period directly following t). To ease interpretation, we present a simplified version of the full DAG in which we condense most of the time-variant and time-invariant predictor variables down to the time-invariant covariates ($Z$ terms). We also only present two periods, but the chain of events theoretically runs back to the first observation of $t$ in the series. The light blue node represents the outcome of interest (protests), while the light green node represents the treatment of interest (troops). Any node connected to another indicates a proposed causal relationship, and the direction of the arrow represents the direction of that relationship.

\begin{figure}[t]
	\centering\includegraphics[scale=0.8]{../../Figures/Chapter-Protests/fig-dag-protest-simple.png}
	\caption{Directed Acyclic Graph (DAG) showing the theoretical model of protest across time periods.}
	\label{fig:dagtroops}
\end{figure}

Using this model as our starting point, we are able to generate a number of adjustment sets---variables that, when included in the model, will ensure there is no unmeasured confounding. Notably, this rests entirely on the notion that we have the ``right'' theoretical model. There are a number of possible adjustment sets we can use given the current model, but they all accomplish the same basic task. If we have included causal relationships in our theoretical model that do not actually exist, or if we have omitted key causal relationships that \textit{do} actually exist, then the implications of the model and our ability to isolate causal effects may change. The degree to which these changes would affect our ability to assess the causal relationships we are proposing depends entirely on the specific connections that would change. Assuming for present purposes that our model is sufficient, we can now estimate the denominator described in Equation \ref{eq:structuralweights}.

Once we have calculated the structural weights using this method, we can now proceed to estimate the average treatment effect (ATE) of troop deployments on protest activity. To do so we estimate a series of multilevel negative binomial regressions predicting the number of protests in a country year using the troop deployment variable and treatment history (i.e. the cumulative sum of deployments through time $t-2$) as predictor variables.\footnote{See \citeasnoun{Hill2013} for more information on the use of multilevel models for causal inference.}  Notably, these models weight the observations according to the structural weights we calculated above. US military deployments are generally stable \textit{within} countries, with substantial variation \textit{between} countries. For example, Germany's troop levels are high and relatively stable over the period that we study. In other cases, troop level are low, but also relatively stable. There are, however, some cases where troop levels increase and decrease radically at various points throughout the 1990--2018 period. These sudden changes are typically associated with large military operations, like the 1999 war in Kosovo or the 2003 Iraq War. This extreme variability makes estimating the outcome models somewhat difficult because we end up with extremely large weights for a small set of observations. To address this problem, we estimate the models multiple times using several different truncation points for the weights to better assess the sensitivity of our estimates to the weighted sample. The weights effectively create a pseudo sample of data by replicating observations according to their score. For example, an observation with a score of 4 would be copied four times when we run the model. Given these cases where we see very rapid and extreme changes in US military deployment levels we encounter a situation where the weights are often enormous (e.g. weighting scores of 50,000$+$). There is some question about the proper size of the weights and how to deal with very large or very small weights. Because we are dealing with some exceptionally large weights, we estimate our outcome model multiple times using different truncation points to cut down on the number of extreme values, and to assess how sensitive our estimates of the ATE are to changes in the weights.\footnote{There is no clearly ``correct'' way to deal with extreme weight values. \citeasnoun{ColeHernan2008} note that in the context of binary treatment variables the average of the weights should be approximately 1, but beyond this there is relatively little guidance of which we are aware. One approach is to trim weight scores, which we employ here. Specifically, we set multiple thresholds at 10, 50, 500, 1,000, 5,000, and 10,000. Observations where the calculated weight falls above the threshold are reset to the maximum threshold. For example, when estimating our models using the 500 threshold, a structural weight that is calculated to be 1,000 would be re-coded to be 500. This approach is useful in that it does not require us to throw away data. There is a clear gain in efficiency as a result of increasing the effective number of observations, but too few or too many pseudo observations can bias the estimates. Hence, we present all of these points to assess bias and sensitivity.} We display this information below in the results section.



